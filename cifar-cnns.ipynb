{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "cifar-cnns.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJNcmiZpjJF",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR Classification using Convolutional Nueral Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ci3sPKXpjJG",
        "colab_type": "text"
      },
      "source": [
        "This notebook aims to illustrate how tensorflow 1.4 can be used to construct different models to perform CIFAR classification. The different models together with their results are presented here below.\n",
        "\n",
        "**Please note that this notebook is still under construction and therefore something might not be fully clear or in fully functional form.**\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kRuRh7ZpjJH",
        "colab_type": "text"
      },
      "source": [
        "### Basic overview and setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcyePY1pjJI",
        "colab_type": "text"
      },
      "source": [
        "There are a number of packages needed for this repository. These are listed in requirements.txt. However, some will be needed to run this notebook and these are imported here below. The _os_ and _datetime_ packages are needed to set the log filenames, _tensorflow_ to define the graphs and the repo package _pcyf_ where the functions are defined to import the models and any needed utility functions.\n",
        "\n",
        "The log level is set to 2 to suppress build warnings when setting up the tensorflow graphs. \n",
        "\n",
        "Finally, some test constant variables such as the number of epochs and batch_size are also defined here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMYvSPl1pjJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "from pycf import models as models\n",
        "from pycf.data_providers import CIFAR10DataProvider\n",
        "from pycf.utils import show_graph, display_image\n",
        "\n",
        "# Set log level to suppress build warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Model variables to be kept constant throughout all the tests\n",
        "NUM_EPOCH = 10\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YQ-2gGMpjJM",
        "colab_type": "text"
      },
      "source": [
        "The files downloaded from the CIFAR <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">website</a> are in pickle form. It would be easier if these were in _tfrecord_ format in order to be loaded into the graph. The format _tfrecord_ is a tensorflow defined binary format. It allows partial loading and hence not all images need to be in-memory for processing. The loading provider could be in a form of a FIFO where batches are loaded and processed sequentially. \n",
        "\n",
        "To convert the downloaded data to _tfrecord_, make sure the data files are in a _data/_ subfolder and then run `python -m pycf.data_prep` in the root directory.\n",
        "\n",
        "Since the data is read through a _tfrecord_ the data provider can have its operations defined in the main graph. The class `CIFAR10DataProvider` in `pycf.data_providers` manages all the loading from the tfrecords. This designed function takes filenames from the `config/settings.py` file and defines a dataset to represent the data. the `CIFAR10DataProvider.next()` can be used to define the function for subsequent batches.\n",
        "\n",
        "In the example below the batch of images is resized using the `tf.image.resize_images` function for better visualization. \n",
        "\n",
        "Since, everything is defined as tensors in the default graph, this graph needs to be run for the output to be produced. This is done using the `sess.run` after the variables have been initialized. An example image is shown. This is the image with index `sample_image_index` in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnCRXxNpjJN",
        "colab_type": "code",
        "colab": {},
        "outputId": "86ed2e97-14af-41e8-9ac1-ef52b345a30a"
      },
      "source": [
        "# Sample image for context\n",
        "sample_image_index = 1\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    \n",
        "    # Define data provider\n",
        "    train_data = CIFAR10DataProvider(batch_size=BATCH_SIZE, epochs=NUM_EPOCH, shape='3d')\n",
        "    \n",
        "    # Define next batch function from data provider\n",
        "    next_example, next_labels = train_data.next()\n",
        "    label_map = train_data.label_map()\n",
        "    \n",
        "    # Resize image for better visuals\n",
        "    resized_images = tf.image.resize_images(next_example, [128, 128], tf.image.ResizeMethod.AREA)\n",
        "\n",
        "    # Run tensorflow graph to produce numpy outputs from tensors\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        imgs, labels = sess.run([resized_images, next_labels])\n",
        "    \n",
        "    \n",
        "print('Possible labels: ' + ', '.join(label_map))\n",
        "display_image(imgs[sample_image_index])\n",
        "print('Associated label:   ' + label_map[list(labels[sample_image_index]).index(1.0)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Associated label:   bird\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdd5x_M-pjJR",
        "colab_type": "text"
      },
      "source": [
        "The data provider which is defined in `pycf.data_providers` is a class which handles the `tf.data.Dataset` object. Once the data provider is created, the `.next()` function can be called to create a function to provide the next example and associated label in one-of-k encoding.\n",
        "\n",
        "This next example and label can be next used to a graph found in `pycf.models`. This definition function returns some metrics ops such as error and accuracy and train ops such as summary and train step.\n",
        "\n",
        "Here we are using a function called `show_graph` to show the graph in the notebook. This graph can also be seen on _Tensorboard_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0SQc9sU0pjJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Graph\n",
        "modelA = tf.Graph()\n",
        "\n",
        "\n",
        "with modelA.as_default():\n",
        "    \n",
        "    # Create dataset and function for next example\n",
        "    train_data = CIFAR10DataProvider(batch_size=batch_size, epochs=num_epochs, shape='3d')\n",
        "    next_example, next_label = train_data.next()\n",
        "     \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        \n",
        "        [imgs] = sess.run([next_example])\n",
        "        display_flat_image(imgs[2])\n",
        "        \n",
        "    # Define model\n",
        "    # metrics_ops, train_ops = models.fc6(next_example, next_label)\n",
        "    #show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn_dYmdcpjJV",
        "colab_type": "text"
      },
      "source": [
        "The model can now be trained to classify the different CIFAR images. Here we are training for `num_epochs * total_batches` steps. This essentailly means we are training for `num_epochs` loops through the training set. \n",
        "\n",
        "First we are defining the `train_writer` of the graph. This is used to write summaries to `Tensorboard`. We are then starting a session, and within the session we are:\n",
        "    1. Initializing the variables\n",
        "    2. Looping for the number of steps and running the graph. Since train_ops contains the train_step operation, this means \n",
        "        that the optimizer.minimize(error) is run. If this op is not run, the graph would not learn.\n",
        "    3. Save the data to tensorboard on each loop and aggregate the error in variables.\n",
        "    4. Print the error every 400 batches ie every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSsn3IbpjJV",
        "colab_type": "code",
        "colab": {},
        "outputId": "97141484-6dd4-467a-e9c7-a5b390b441d1"
      },
      "source": [
        "\n",
        "\n",
        "with modelA.as_default():\n",
        "    \n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    train_writer = tf.summary.FileWriter(os.path.join('tf-log', timestamp, 'train'), graph=tf.get_default_graph())\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "    \n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        \n",
        "        running_err = 0\n",
        "        running_acc = 0\n",
        "        train_step = 0\n",
        "        \n",
        "        while train_step < num_epochs*total_batches:\n",
        "            train_info, metrics = sess.run([train_ops, metrics_ops])\n",
        "            \n",
        "            train_writer.add_summary(train_info['summary'], train_step)\n",
        "            running_err += metrics['error']\n",
        "            running_acc += metrics['accuracy']\n",
        "            \n",
        "            if (train_step%total_batches==0) and (train_step!=0):\n",
        "                print('Batch {0:02}\\t| Average Error = {1:02.2f}\\t| Average Accuracy = {2:.4f}'\n",
        "                      .format(train_step, running_err/total_batches, running_acc/total_batches))\n",
        "               \n",
        "                running_err = 0\n",
        "                running_acc = 0\n",
        "            train_step +=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 400\t| Average Error = 2.33\t| Average Accuracy = 0.1136\n",
            "Batch 800\t| Average Error = 2.22\t| Average Accuracy = 0.1316\n",
            "Batch 1200\t| Average Error = 2.15\t| Average Accuracy = 0.1476\n",
            "Batch 1600\t| Average Error = 2.08\t| Average Accuracy = 0.1633\n",
            "Batch 2000\t| Average Error = 2.04\t| Average Accuracy = 0.1776\n",
            "Batch 2400\t| Average Error = 1.99\t| Average Accuracy = 0.1911\n",
            "Batch 2800\t| Average Error = 1.95\t| Average Accuracy = 0.2026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-ae92cceaf07c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mtrain_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\mark\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\mark\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\mark\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\mark\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\mark\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xwdrxi2pjJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}